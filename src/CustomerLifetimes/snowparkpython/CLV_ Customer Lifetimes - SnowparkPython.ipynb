{"cells":[{"cell_type":"markdown","source":["##Calculating the Probability of Future Customer Engagement\n\n**NOTE:** Snowpark Implementation\n\nIn non-subscription retail models, customers come and go with no long-term commitments, making it very difficult to determine whether a customer will return in the future. Determining the probability that a customer will re-engage is critical to the design of effective marketing campaigns. Different messaging and promotions may be required to incentivize customers who have likely dropped out to return to our stores. Engaged customers may be more responsive to marketing that encourages them to expand the breadth and scale of purchases with us. Understanding where our customers land with regard to the probability of future engagement is critical to tailoring our marketing efforts to them.  \n\nThe *Buy 'til You Die* (BTYD) models popularized by Peter Fader and others leverage two basic customer metrics, *i.e.* the recency of a customer's last engagement and the frequency of repeat transactions over a customer's lifetime, to derive a probability of future re-engagement. This is done by fitting customer history to curves describing the distribution of purchase frequencies and engagement drop-off following a prior purchase. The math behind these models is fairly complex but thankfully it's been encapsulated in the [lifetimes](https://pypi.org/project/Lifetimes/) library, making it much easier for traditional enterprises to employ. The purpose of this notebook is to examine how these models may be applied to customer transaction history and how they may be deployed for integration in marketing processes."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c8c43652-1eda-4ef7-8b39-2d8c922ab409"}}},{"cell_type":"markdown","source":["###Step 1: Setup the Environment\n\nTo run this notebook, you need to attach to a **Databricks ML Runtime** cluster leveraging Databricks version 6.5+. This version of the Databricks runtime will provide access to many of the pre-configured libraries used here.  Still, there are additional Python libraries which you will need to install and attach to your cluster.  These are:</p>\n\n* xlrd\n* lifetimes==0.10.1\n* nbconvert\n\nTo install these libraries in your Databricks workspace, please follow [these steps](https://docs.databricks.com/libraries.html#workspace-libraries) using the PyPI library source in combination with the bullet-pointed library names in the provided list.  Once installed, please be sure to [attach](https://docs.databricks.com/libraries.html#install-a-library-on-a-cluster) these libraries to the cluster with which you are running this notebook."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ab4522eb-7437-4fdf-9b3a-d715ff6db306"}}},{"cell_type":"markdown","source":["With the libraries installed, let's load a sample dataset with which we can examine the BTYD models. The dataset we will use is the [Online Retail Data Set](http://archive.ics.uci.edu/ml/datasets/Online+Retail) available from the UCI Machine Learning Repository.  This dataset is made available as a Microsoft Excel workbook (XLSX).  Having downloaded this XLSX file to our local system, we can load it into our Databricks environment by following the steps provided [here](https://docs.databricks.com/data/tables.html#create-table-ui). Please note when performing the file import, you don't need to select the *Create Table with UI* or the *Create Table in Notebook* options to complete the import process. Also, the name of the XLSX file will be modified upon import as it includes an unsupported space character.  As a result, we will need to programmatically locate the new name for the file assigned by the import process.\n\nAssuming we've uploaded the XLSX to the */FileStore/tables/online_retail/*, we can access it as follows:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4a2d87e4-6244-40f0-9fc9-746ac693d18e"}}},{"cell_type":"code","source":["from IPython.display import display, HTML, Image , Markdown\n\n# Maximize View\ndisplay(HTML(\"<style>.container { width:90% !important; }</style>\"))\n\nimport logging\nimport sys\nimport os ,json\nimport dotenv \nimport pandas as pd\nfrom snowflake.snowpark import Session\nimport snowflake.snowpark.functions as F\nimport snowflake.snowpark.types as T\n\nlogging.basicConfig(stream=sys.stdout, level=logging.CRITICAL)\n\n#Load the snowflake login information from env file\ndotenv.load_dotenv('/dbfs/FileStore/tables/sflk.env')\n\n#Create a snowpark session\nconnection_parameters = {\n  \"account\": os.getenv('DEMO_ACCOUNT'),\n  \"user\": os.getenv('DEMO_USER'),\n  \"password\": os.getenv('DEMO_PWD'),\n  \"role\": \"sysadmin\",\n  \"warehouse\": os.getenv('DEMO_WH'),\n  \"database\": 'stage_db',\n  \"schema\": 'public'\n}\n\nsession = Session.builder.configs(connection_parameters).create()\nprint(session.sql(\"select current_account() ,current_warehouse(), current_database(), current_schema()\").collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d12bddc-934d-4816-a558-8409b24a6950"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;IPython.core.display.HTML object&gt;\n[Row(CURRENT_ACCOUNT()=&#39;VA_DEMO03&#39;, CURRENT_WAREHOUSE()=&#39;LAB_WH&#39;, CURRENT_DATABASE()=&#39;STAGE_DB&#39;, CURRENT_SCHEMA()=&#39;PUBLIC&#39;)]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;IPython.core.display.HTML object&gt;\n[Row(CURRENT_ACCOUNT()=&#39;VA_DEMO03&#39;, CURRENT_WAREHOUSE()=&#39;LAB_WH&#39;, CURRENT_DATABASE()=&#39;STAGE_DB&#39;, CURRENT_SCHEMA()=&#39;PUBLIC&#39;)]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\n\nxlsx_filename = '/dbfs/FileStore/tables/Online_Retail.xlsx'\n\n# schema of the excel spreadsheet data range\norders_schema = {\n  'InvoiceNo':str,\n  'StockCode':str,\n  'Description':str,\n  'Quantity':np.int64,\n  'InvoiceDate':np.datetime64,\n  'UnitPrice':np.float64,\n  'CustomerID':str,\n  'Country':str  \n  }\n\n# read spreadsheet to pandas dataframe\n# the xlrd library must be installed for this step to work \norders_pd = pd.read_excel(\n  xlsx_filename, \n  sheet_name='Online Retail',\n  header=0, # first row is header\n  dtype=orders_schema\n  ,engine='openpyxl'\n  )\n\n# display first few rows from the dataset\norders_pd.head(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9c0e13cb-8b00-4857-8be4-37b3d0fc5ac7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[2]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[2]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>InvoiceNo</th>\n      <th>StockCode</th>\n      <th>Description</th>\n      <th>Quantity</th>\n      <th>InvoiceDate</th>\n      <th>UnitPrice</th>\n      <th>CustomerID</th>\n      <th>Country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>536365</td>\n      <td>85123A</td>\n      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n      <td>6</td>\n      <td>2010-12-01 08:26:00</td>\n      <td>2.55</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>536365</td>\n      <td>71053</td>\n      <td>WHITE METAL LANTERN</td>\n      <td>6</td>\n      <td>2010-12-01 08:26:00</td>\n      <td>3.39</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>536365</td>\n      <td>84406B</td>\n      <td>CREAM CUPID HEARTS COAT HANGER</td>\n      <td>8</td>\n      <td>2010-12-01 08:26:00</td>\n      <td>2.75</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>536365</td>\n      <td>84029G</td>\n      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n      <td>6</td>\n      <td>2010-12-01 08:26:00</td>\n      <td>3.39</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>536365</td>\n      <td>84029E</td>\n      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n      <td>6</td>\n      <td>2010-12-01 08:26:00</td>\n      <td>3.39</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>536365</td>\n      <td>22752</td>\n      <td>SET 7 BABUSHKA NESTING BOXES</td>\n      <td>2</td>\n      <td>2010-12-01 08:26:00</td>\n      <td>7.65</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>536365</td>\n      <td>21730</td>\n      <td>GLASS STAR FROSTED T-LIGHT HOLDER</td>\n      <td>6</td>\n      <td>2010-12-01 08:26:00</td>\n      <td>4.25</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>536366</td>\n      <td>22633</td>\n      <td>HAND WARMER UNION JACK</td>\n      <td>6</td>\n      <td>2010-12-01 08:28:00</td>\n      <td>1.85</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>536366</td>\n      <td>22632</td>\n      <td>HAND WARMER RED POLKA DOT</td>\n      <td>6</td>\n      <td>2010-12-01 08:28:00</td>\n      <td>1.85</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>536367</td>\n      <td>84879</td>\n      <td>ASSORTED COLOUR BIRD ORNAMENT</td>\n      <td>32</td>\n      <td>2010-12-01 08:34:00</td>\n      <td>1.69</td>\n      <td>13047</td>\n      <td>United Kingdom</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>InvoiceNo</th>\n      <th>StockCode</th>\n      <th>Description</th>\n      <th>Quantity</th>\n      <th>InvoiceDate</th>\n      <th>UnitPrice</th>\n      <th>CustomerID</th>\n      <th>Country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>536365</td>\n      <td>85123A</td>\n      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n      <td>6</td>\n      <td>2010-12-01 08:26:00</td>\n      <td>2.55</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>536365</td>\n      <td>71053</td>\n      <td>WHITE METAL LANTERN</td>\n      <td>6</td>\n      <td>2010-12-01 08:26:00</td>\n      <td>3.39</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>536365</td>\n      <td>84406B</td>\n      <td>CREAM CUPID HEARTS COAT HANGER</td>\n      <td>8</td>\n      <td>2010-12-01 08:26:00</td>\n      <td>2.75</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>536365</td>\n      <td>84029G</td>\n      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n      <td>6</td>\n      <td>2010-12-01 08:26:00</td>\n      <td>3.39</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>536365</td>\n      <td>84029E</td>\n      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n      <td>6</td>\n      <td>2010-12-01 08:26:00</td>\n      <td>3.39</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>536365</td>\n      <td>22752</td>\n      <td>SET 7 BABUSHKA NESTING BOXES</td>\n      <td>2</td>\n      <td>2010-12-01 08:26:00</td>\n      <td>7.65</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>536365</td>\n      <td>21730</td>\n      <td>GLASS STAR FROSTED T-LIGHT HOLDER</td>\n      <td>6</td>\n      <td>2010-12-01 08:26:00</td>\n      <td>4.25</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>536366</td>\n      <td>22633</td>\n      <td>HAND WARMER UNION JACK</td>\n      <td>6</td>\n      <td>2010-12-01 08:28:00</td>\n      <td>1.85</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>536366</td>\n      <td>22632</td>\n      <td>HAND WARMER RED POLKA DOT</td>\n      <td>6</td>\n      <td>2010-12-01 08:28:00</td>\n      <td>1.85</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>536367</td>\n      <td>84879</td>\n      <td>ASSORTED COLOUR BIRD ORNAMENT</td>\n      <td>32</td>\n      <td>2010-12-01 08:34:00</td>\n      <td>1.69</td>\n      <td>13047</td>\n      <td>United Kingdom</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["The data in the workbook are organized as a range in the Online Retail spreadsheet.  Each record represents a line item in a sales transaction. The fields included in the dataset are:\n\n| Field | Description |\n|-------------:|-----:|\n|InvoiceNo|A 6-digit integral number uniquely assigned to each transaction|\n|StockCode|A 5-digit integral number uniquely assigned to each distinct product|\n|Description|The product (item) name|\n|Quantity|The quantities of each product (item) per transaction|\n|InvoiceDate|The invoice date and a time in mm/dd/yy hh:mm format|\n|UnitPrice|The per-unit product price in pound sterling (£)|\n|CustomerID| A 5-digit integral number uniquely assigned to each customer|\n|Country|The name of the country where each customer resides|\n\nOf these fields, the ones of particular interest for our work are InvoiceNo which identifies the transaction, InvoiceDate which identifies the date of that transaction, and CustomerID which uniquely identifies the customer across multiple transactions. (In a separate notebook, we will examine the monetary value of the transactions through the UnitPrice and Quantity fields.)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"63f62e6e-1309-4e2f-8c85-ed1e0a2083aa"}}},{"cell_type":"markdown","source":["###Step 2: Explore the Dataset\n\nTo enable the exploration of the data using SQL statements, let's flip the pandas DataFrame into a Spark DataFrame and persist it as a temporary view:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"54da5e21-1c6f-4005-89bc-0a33fdd898b6"}}},{"cell_type":"code","source":["\nt = session.create_dataframe([(1, \"one\"), (2, \"two\")], schema=[\"col_a\", \"col_b\"])\nt.show()\ntype(session)\ndisplay(orders_pd)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"95f79e62-656d-49c2-b743-665cd6605de1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">---------------------\n|&#34;COL_A&#34;  |&#34;COL_B&#34;  |\n---------------------\n|1        |one      |\n|2        |two      |\n---------------------\n\n       InvoiceNo StockCode  ... CustomerID         Country\n0         536365    85123A  ...      17850  United Kingdom\n1         536365     71053  ...      17850  United Kingdom\n2         536365    84406B  ...      17850  United Kingdom\n3         536365    84029G  ...      17850  United Kingdom\n4         536365    84029E  ...      17850  United Kingdom\n...          ...       ...  ...        ...             ...\n541904    581587     22613  ...      12680          France\n541905    581587     22899  ...      12680          France\n541906    581587     23254  ...      12680          France\n541907    581587     23255  ...      12680          France\n541908    581587     22138  ...      12680          France\n\n[541909 rows x 8 columns]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">---------------------\n&#34;COL_A&#34;  |&#34;COL_B&#34;  |\n---------------------\n1        |one      |\n2        |two      |\n---------------------\n\n       InvoiceNo StockCode  ... CustomerID         Country\n0         536365    85123A  ...      17850  United Kingdom\n1         536365     71053  ...      17850  United Kingdom\n2         536365    84406B  ...      17850  United Kingdom\n3         536365    84029G  ...      17850  United Kingdom\n4         536365    84029E  ...      17850  United Kingdom\n...          ...       ...  ...        ...             ...\n541904    581587     22613  ...      12680          France\n541905    581587     22899  ...      12680          France\n541906    581587     23254  ...      12680          France\n541907    581587     23255  ...      12680          France\n541908    581587     22138  ...      12680          France\n\n[541909 rows x 8 columns]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import snowflake.snowpark.functions as F\nimport snowflake.snowpark.types as T\n\n\ntype(orders_pd)\nt = session.create_dataframe(orders_pd)\n\norders = t.select(\n    F.col('\\\"InvoiceNo\\\"').cast(T.StringType()).as_('InvoiceNo')\n    ,F.col('\\\"StockCode\\\"').cast(T.StringType()).as_('StockCode')\n    ,F.col('\\\"Description\\\"').cast(T.StringType()).as_('Description')\n    ,F.col('\\\"Quantity\\\"').cast(T.IntegerType()).as_('Quantity')\n    ,F.call_builtin(\"to_date\", F.col('\\\"InvoiceDate\\\"').cast(T.StringType())).as_('InvoiceDate') \n    ,F.col('\\\"UnitPrice\\\"').cast(T.FloatType()).as_('UnitPrice')\n    ,F.col('\\\"CustomerID\\\"').cast(T.StringType()).as_('CustomerID')\n    ,F.col('\\\"Country\\\"').cast(T.StringType()).as_('Country')\n)\n\n\norders.write.mode(\"overwrite\").save_as_table(\"orders\")\n\ndisplay(orders.limit(5).to_pandas())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f720a893-3ed9-46ce-9b31-a9759cbc1896"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">  INVOICENO STOCKCODE  ... CUSTOMERID         COUNTRY\n0    536365    85123A  ...      17850  United Kingdom\n1    536365     71053  ...      17850  United Kingdom\n2    536365    84406B  ...      17850  United Kingdom\n3    536365    84029G  ...      17850  United Kingdom\n4    536365    84029E  ...      17850  United Kingdom\n\n[5 rows x 8 columns]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">  INVOICENO STOCKCODE  ... CUSTOMERID         COUNTRY\n0    536365    85123A  ...      17850  United Kingdom\n1    536365     71053  ...      17850  United Kingdom\n2    536365    84406B  ...      17850  United Kingdom\n3    536365    84029G  ...      17850  United Kingdom\n4    536365    84029E  ...      17850  United Kingdom\n\n[5 rows x 8 columns]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Examining the transaction activity in our dataset, we can see the first transaction occurs December 1, 2010 and the last is on December 9, 2011 making this a dataset that's a little more than 1 year in duration. The daily transaction count shows there is quite a bit of volatility in daily activity for this online retailer:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a42f2d48-5107-47be-86ce-7770037a2ecc"}}},{"cell_type":"code","source":["display(Markdown(f'unique transactions by date '))\n\n# SELECT \n#   TO_DATE(InvoiceDate) as InvoiceDate,\n#   COUNT(DISTINCT InvoiceNo) as Transactions\n# FROM orders\n# GROUP BY TO_DATE(InvoiceDate)\n# ORDER BY InvoiceDate;\n\n#notice the re-use of the alias invoicedate in the groupby expression\ntxn_by_date_df = session.sql(f'''\n    SELECT \n      TO_DATE(InvoiceDate) as InvoiceDate,\n      COUNT(DISTINCT InvoiceNo) as Transactions\n    FROM orders\n    GROUP BY InvoiceDate\n    ORDER BY InvoiceDate\n''')\ndisplay(txn_by_date_df.limit(5).to_pandas())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0f29913f-3c6e-4f22-b9a4-f9fd2ac096ea"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n  INVOICEDATE  TRANSACTIONS\n0  2010-12-01           143\n1  2010-12-02           167\n2  2010-12-03           108\n3  2010-12-05            95\n4  2010-12-06           133\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n  INVOICEDATE  TRANSACTIONS\n0  2010-12-01           143\n1  2010-12-02           167\n2  2010-12-03           108\n3  2010-12-05            95\n4  2010-12-06           133\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["We can smooth this out a bit by summarizing activity by month. It's important to keep in mind that December 2011 only consists of 9 days so the sales decline graphed for the last month should most likely be ignored:\n\nNOTE We will hide the SQL behind each of the following result sets for ease of viewing.  To view this code, simply click the **Show code** item above each of the following charts."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"20738932-3dc0-4e80-a8f6-f27185a141b1"}}},{"cell_type":"code","source":["display(Markdown(f'unique transactions by month '))\n\n# SELECT \n#   TRUNC(InvoiceDate, 'month') as InvoiceMonth,\n#   COUNT(DISTINCT InvoiceNo) as Transactions\n# FROM orders\n# GROUP BY TRUNC(InvoiceDate, 'month') \n# ORDER BY InvoiceMonth;\n\ntxn_by_mon_df = session.sql(f'''\n    SELECT \n      TRUNC(TO_DATE(InvoiceDate), 'month') as InvoiceMonth,\n      COUNT(DISTINCT InvoiceNo) as Transactions\n    FROM orders\n    GROUP BY InvoiceMonth\n    ORDER BY InvoiceMonth\n''')\n\ndisplay(txn_by_mon_df.limit(5).to_pandas())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"89ad385d-20cb-473d-bbf3-75529add1aa0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n  INVOICEMONTH  TRANSACTIONS\n0   2010-12-01          2025\n1   2011-01-01          1476\n2   2011-02-01          1393\n3   2011-03-01          1983\n4   2011-04-01          1744\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n  INVOICEMONTH  TRANSACTIONS\n0   2010-12-01          2025\n1   2011-01-01          1476\n2   2011-02-01          1393\n3   2011-03-01          1983\n4   2011-04-01          1744\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["For the little more than 1-year period for which we have data, we see over four-thousand unique customers.  These customers generated about twenty-two thousand unique transactions:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a6f6ebed-7131-4b8c-a69a-19cabf416bcd"}}},{"cell_type":"code","source":["display(Markdown(f'unique customers and transactions '))\n\n# SELECT\n#  COUNT(DISTINCT CustomerID) as Customers,\n#  COUNT(DISTINCT InvoiceNo) as Transactions\n# FROM orders\n# WHERE CustomerID IS NOT NULL;\n\ncust_to_txn_df = session.sql(f'''\n    SELECT\n     COUNT(DISTINCT CustomerID) as Customers,\n     COUNT(DISTINCT InvoiceNo) as Transactions\n    FROM orders\n    WHERE CustomerID IS NOT NULL\n''')\ndisplay(cust_to_txn_df.limit(5).to_pandas())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7b4f8420-230f-4ab5-a565-32df585ed250"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n   CUSTOMERS  TRANSACTIONS\n0       4372         22190\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n   CUSTOMERS  TRANSACTIONS\n0       4372         22190\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["A little quick math may lead us to estimate that, on average, each customer is responsible for about 5 transactions, but this would not provide an accurate representation of customer activity.\n\nInstead, if we count the unique transactions by customer and then examine the frequency of these values, we see that many of the customers have engaged in a single transaction. The distribution of the count of repeat purchases declines from there in a manner that we may describe as negative binomial distribution (which is the basis of the NBD acronym included in the name of most BTYD models):"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8483694f-a717-4210-8d88-d1cbfde8afce"}}},{"cell_type":"code","source":["display(Markdown(f'the distribution of per-customer transaction counts '))\n\n# SELECT\n#   x.Transactions,\n#   COUNT(x.*) as Occurrences\n# FROM (\n#   SELECT\n#     CustomerID,\n#     COUNT(DISTINCT InvoiceNo) as Transactions \n#   FROM orders\n#   WHERE CustomerID IS NOT NULL\n#   GROUP BY CustomerID\n#   ) x\n# GROUP BY \n#   x.Transactions\n# ORDER BY\n#   x.Transactions;\n    \nt_df = session.sql('''\nSELECT\n  x.Transactions,\n  COUNT(x.*) as Occurrences\nFROM (\n  SELECT\n    CustomerID,\n    COUNT(DISTINCT InvoiceNo) as Transactions \n  FROM orders\n  WHERE CustomerID IS NOT NULL\n  GROUP BY CustomerID\n  ) x\nGROUP BY \n  x.Transactions\nORDER BY\n  x.Transactions\n''')\ndisplay(t.limit(5).to_pandas())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8e472bc4-a78b-4ff1-809a-3531c2fe37a2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n  InvoiceNo StockCode  ... CustomerID         Country\n0    536365    85123A  ...      17850  United Kingdom\n1    536365     71053  ...      17850  United Kingdom\n2    536365    84406B  ...      17850  United Kingdom\n3    536365    84029G  ...      17850  United Kingdom\n4    536365    84029E  ...      17850  United Kingdom\n\n[5 rows x 8 columns]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n  InvoiceNo StockCode  ... CustomerID         Country\n0    536365    85123A  ...      17850  United Kingdom\n1    536365     71053  ...      17850  United Kingdom\n2    536365    84406B  ...      17850  United Kingdom\n3    536365    84029G  ...      17850  United Kingdom\n4    536365    84029E  ...      17850  United Kingdom\n\n[5 rows x 8 columns]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["If we alter our last analysis to group a customer's transactions that occur on the same date into a single transaction - a pattern that aligns with metrics we will calculate later - we see that a few more customers are identified as non-repeat customers but the overall pattern remains the same:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1df64d07-9b49-4f86-8f23-6b2e6347fe54"}}},{"cell_type":"code","source":["display(Markdown(f'''\n    the distribution of per-customer transaction counts with consideration of same-day transactions as a single transaction \n'''))\n\n# SELECT\n#   x.Transactions,\n#   COUNT(x.*) as Occurances\n# FROM (\n#   SELECT\n#     CustomerID,\n#     COUNT(DISTINCT TO_DATE(InvoiceDate)) as Transactions\n#   FROM orders\n#   WHERE CustomerID IS NOT NULL\n#   GROUP BY CustomerID\n#   ) x\n# GROUP BY \n#   x.Transactions\n# ORDER BY\n#   x.Transactions;\n\n    \nt_df = session.sql('''\nSELECT\n  x.Transactions,\n  COUNT(x.*) as Occurances\nFROM (\n  SELECT\n    CustomerID,\n    COUNT(DISTINCT TO_DATE(InvoiceDate)) as Transactions\n  FROM orders\n  WHERE CustomerID IS NOT NULL\n  GROUP BY CustomerID\n  ) x\nGROUP BY \n  x.Transactions\nORDER BY\n  x.Transactions\n''')\ndisplay(t.limit(5).to_pandas())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b52ccbbc-28c1-47f1-b2d2-26f39acb5d08"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n  InvoiceNo StockCode  ... CustomerID         Country\n0    536365    85123A  ...      17850  United Kingdom\n1    536365     71053  ...      17850  United Kingdom\n2    536365    84406B  ...      17850  United Kingdom\n3    536365    84029G  ...      17850  United Kingdom\n4    536365    84029E  ...      17850  United Kingdom\n\n[5 rows x 8 columns]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n  InvoiceNo StockCode  ... CustomerID         Country\n0    536365    85123A  ...      17850  United Kingdom\n1    536365     71053  ...      17850  United Kingdom\n2    536365    84406B  ...      17850  United Kingdom\n3    536365    84029G  ...      17850  United Kingdom\n4    536365    84029E  ...      17850  United Kingdom\n\n[5 rows x 8 columns]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Focusing on customers with repeat purchases, we can examine the distribution of the days between purchase events. What's important to note here is that most customers return to the site within 2 to 3 months of a prior purchase.  Longer gaps do occur but significantly fewer customers have longer gaps between returns.  This is important to understand in the context of our BYTD models in that the time since we last saw a customer is a critical factor to determining whether they will ever come back with the probability of return dropping as more and more time passes since a customer's last purchase event:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a55c98de-6a2b-4d56-b73c-8dc122addca6"}}},{"cell_type":"code","source":["display(Markdown(f'''\n    distribution of per-customer average number of days between purchase events\n'''))\n\n# WITH CustomerPurchaseDates\n#   AS (\n#     SELECT DISTINCT\n#       CustomerID,\n#       TO_DATE(InvoiceDate) as InvoiceDate\n#     FROM orders \n#     WHERE CustomerId IS NOT NULL\n#     )\n# SELECT -- Per-Customer Average Days Between Purchase Events\n#   AVG(\n#     DATEDIFF(a.NextInvoiceDate, a.InvoiceDate)\n#     ) as AvgDaysBetween\n# FROM ( -- Purchase Event and Next Purchase Event by Customer\n#   SELECT \n#     x.CustomerID,\n#     x.InvoiceDate,\n#     MIN(y.InvoiceDate) as NextInvoiceDate\n#   FROM CustomerPurchaseDates x\n#   INNER JOIN CustomerPurchaseDates y\n#     ON x.CustomerID=y.CustomerID AND x.InvoiceDate < y.InvoiceDate\n#   GROUP BY \n#     x.CustomerID,\n#     x.InvoiceDate\n#     ) a\n# GROUP BY CustomerID\n\nt_df = session.sql('''\nWITH CustomerPurchaseDates\n  AS (\n    SELECT DISTINCT\n      CustomerID,\n      TO_DATE(InvoiceDate) as InvoiceDate\n    FROM orders \n    WHERE CustomerId IS NOT NULL\n    )\nSELECT -- Per-Customer Average Days Between Purchase Events\n  AVG(\n    DATEDIFF(a.NextInvoiceDate, a.InvoiceDate)\n    ) as AvgDaysBetween\nFROM ( -- Purchase Event and Next Purchase Event by Customer\n  SELECT \n    x.CustomerID,\n    x.InvoiceDate,\n    MIN(y.InvoiceDate) as NextInvoiceDate\n  FROM CustomerPurchaseDates x\n  INNER JOIN CustomerPurchaseDates y\n    ON x.CustomerID=y.CustomerID AND x.InvoiceDate < y.InvoiceDate\n  GROUP BY \n    x.CustomerID,\n    x.InvoiceDate\n    ) a\nGROUP BY CustomerID\n''')\ndisplay(t.limit(5).to_pandas())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6ef1bb71-bfc2-4a04-b87f-650ae48dc7ad"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n  InvoiceNo StockCode  ... CustomerID         Country\n0    536365    85123A  ...      17850  United Kingdom\n1    536365     71053  ...      17850  United Kingdom\n2    536365    84406B  ...      17850  United Kingdom\n3    536365    84029G  ...      17850  United Kingdom\n4    536365    84029E  ...      17850  United Kingdom\n\n[5 rows x 8 columns]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n  InvoiceNo StockCode  ... CustomerID         Country\n0    536365    85123A  ...      17850  United Kingdom\n1    536365     71053  ...      17850  United Kingdom\n2    536365    84406B  ...      17850  United Kingdom\n3    536365    84029G  ...      17850  United Kingdom\n4    536365    84029E  ...      17850  United Kingdom\n\n[5 rows x 8 columns]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["###Step 3: Calculate Customer Metrics\n\nThe dataset with which we are working consists of raw transactional history.  To apply the BTYD models, we need to derive several per-customer metrics:</p>\n\n* **Frequency** - the number of dates on which a customer made a purchase subsequent to the date of the customer's first purchase\n* **Age (T)** - the number of time units, *e.g.* days, since the date of a customer's first purchase to the current date (or last date in the dataset)\n* **Recency** - the age of the customer (as previously defined) at the time of their last purchase\n\nIt's important to note that when calculating metrics such as customer age that we need to consider when our dataset terminates.  Calculating these metrics relative to today's date can lead to erroneous results.  Given this, we will identify the last date in the dataset and define that as *today's date* for all calculations.\n\nTo get started with these calculations, let's take a look at how they are performed using the built-in functionality of the lifetimes library:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fb34f256-c6f5-4594-b089-b27cbfbb4e93"}}},{"cell_type":"code","source":["import lifetimes\n\n# set the last transaction date as the end point for this historical dataset\ncurrent_date = orders_pd['InvoiceDate'].max()\n\n# calculate the required customer metrics\nmetrics_pd = (\n  lifetimes.utils.summary_data_from_transaction_data(\n    orders_pd,\n    customer_id_col='CustomerID',\n    datetime_col='InvoiceDate',\n    observation_period_end = current_date, \n    freq='D'\n    )\n  )\n\n# display first few rows\nmetrics_pd.head(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"14ce606d-2c9a-4c38-af99-fff0e70a7699"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[29]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[29]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frequency</th>\n      <th>recency</th>\n      <th>T</th>\n    </tr>\n    <tr>\n      <th>CustomerID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12346</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>325.0</td>\n    </tr>\n    <tr>\n      <th>12347</th>\n      <td>6.0</td>\n      <td>365.0</td>\n      <td>367.0</td>\n    </tr>\n    <tr>\n      <th>12348</th>\n      <td>3.0</td>\n      <td>283.0</td>\n      <td>358.0</td>\n    </tr>\n    <tr>\n      <th>12349</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>18.0</td>\n    </tr>\n    <tr>\n      <th>12350</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>310.0</td>\n    </tr>\n    <tr>\n      <th>12352</th>\n      <td>6.0</td>\n      <td>260.0</td>\n      <td>296.0</td>\n    </tr>\n    <tr>\n      <th>12353</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>204.0</td>\n    </tr>\n    <tr>\n      <th>12354</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>232.0</td>\n    </tr>\n    <tr>\n      <th>12355</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>214.0</td>\n    </tr>\n    <tr>\n      <th>12356</th>\n      <td>2.0</td>\n      <td>303.0</td>\n      <td>325.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frequency</th>\n      <th>recency</th>\n      <th>T</th>\n    </tr>\n    <tr>\n      <th>CustomerID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12346</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>325.0</td>\n    </tr>\n    <tr>\n      <th>12347</th>\n      <td>6.0</td>\n      <td>365.0</td>\n      <td>367.0</td>\n    </tr>\n    <tr>\n      <th>12348</th>\n      <td>3.0</td>\n      <td>283.0</td>\n      <td>358.0</td>\n    </tr>\n    <tr>\n      <th>12349</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>18.0</td>\n    </tr>\n    <tr>\n      <th>12350</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>310.0</td>\n    </tr>\n    <tr>\n      <th>12352</th>\n      <td>6.0</td>\n      <td>260.0</td>\n      <td>296.0</td>\n    </tr>\n    <tr>\n      <th>12353</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>204.0</td>\n    </tr>\n    <tr>\n      <th>12354</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>232.0</td>\n    </tr>\n    <tr>\n      <th>12355</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>214.0</td>\n    </tr>\n    <tr>\n      <th>12356</th>\n      <td>2.0</td>\n      <td>303.0</td>\n      <td>325.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["The lifetimes library, like many Python libraries, is single-threaded.  Using this library to derive customer metrics on larger transactional datasets may overwhelm your system or simply take too long to complete. For this reason, let's examine how these metrics can be calculated using the distributed capabilities of Apache Spark.\n\nAs SQL is frequency employed for complex data manipulation, we'll start with a Spark SQL statement.  In this statement, we first assemble each customer's order history consisting of the customer's ID, the date of their first purchase (first_at), the date on which a purchase was observed (transaction_at) and the current date (using the last date in the dataset for this value).  From this history, we can count the number of repeat transaction dates (frequency), the days between the last and first transaction dates (recency), and the days between the current date and first transaction (T) on a per-customer basis:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"313948e4-90ec-4366-bdf0-e6e54cabfebd"}}},{"cell_type":"code","source":["# sql statement to derive summary customer stats\n\n#display(Markdown(f''' '''))\n# SELECT\n#     a.customerid as CustomerID,\n#     CAST(COUNT(DISTINCT a.transaction_at) - 1 as float) as frequency,\n#     CAST(DATEDIFF(MAX(a.transaction_at), a.first_at) as float) as recency,\n#     CAST(DATEDIFF(a.current_dt, a.first_at) as float) as T\n#   FROM ( -- customer order history\n#     SELECT DISTINCT\n#       x.customerid,\n#       z.first_at,\n#       TO_DATE(x.invoicedate) as transaction_at,\n#       y.current_dt\n#     FROM orders x\n#     CROSS JOIN (SELECT MAX(TO_DATE(invoicedate)) as current_dt FROM orders) y                                -- current date (according to dataset)\n#     INNER JOIN (SELECT customerid, MIN(TO_DATE(invoicedate)) as first_at FROM orders GROUP BY customerid) z  -- first order per customer\n#       ON x.customerid=z.customerid\n#     WHERE x.customerid IS NOT NULL\n#     ) a\n#   GROUP BY a.customerid, a.current_dt, a.first_at\n#   ORDER BY CustomerID\n\ndisplay(Markdown(f''' \n**NOTE:** Changes made:\n - DATEDIFF\n'''))\n\nsql = '''\n  SELECT\n    a.customerid as CustomerID,\n    CAST(COUNT(DISTINCT a.transaction_at) - 1 as float) as frequency,\n    CAST(DATEDIFF(day ,MAX(a.transaction_at), a.first_at) as float) as recency,\n    CAST(DATEDIFF(day ,a.current_dt, a.first_at) as float) as T\n  FROM ( -- customer order history\n    SELECT DISTINCT\n      x.customerid,\n      z.first_at,\n      TO_DATE(x.invoicedate) as transaction_at,\n      y.current_dt\n    FROM orders x\n    CROSS JOIN (SELECT MAX(TO_DATE(invoicedate)) as current_dt FROM orders) y                                -- current date (according to dataset)\n    INNER JOIN (SELECT customerid, MIN(TO_DATE(invoicedate)) as first_at FROM orders GROUP BY customerid) z  -- first order per customer\n      ON x.customerid=z.customerid\n    WHERE x.customerid IS NOT NULL\n    ) a\n  GROUP BY a.customerid, a.current_dt, a.first_at\n  ORDER BY CustomerID\n  '''\n# capture stats in dataframe \nmetrics_sql = session.sql(sql)\ndisplay(metrics_sql.limit(5).to_pandas())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2cd09fac-b1e1-4318-ad73-8de149a4007b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n  CUSTOMERID  FREQUENCY  RECENCY      T\n0      12346        0.0      0.0 -325.0\n1      12347        6.0   -365.0 -367.0\n2      12348        3.0   -283.0 -358.0\n3      12349        0.0      0.0  -18.0\n4      12350        0.0      0.0 -310.0\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n  CUSTOMERID  FREQUENCY  RECENCY      T\n0      12346        0.0      0.0 -325.0\n1      12347        6.0   -365.0 -367.0\n2      12348        3.0   -283.0 -358.0\n3      12349        0.0      0.0  -18.0\n4      12350        0.0      0.0 -310.0\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Of course, Spark SQL does not require the DataFrame to be accessed exclusively using a SQL statement.  We may derive this same result using the Programmatic SQL API which may align better with some Data Scientist's preferences.  The code in the next cell is purposely assembled to mirror the structure in the previous SQL statement for the purposes of comparison:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"39e1f110-f037-42a5-abd8-3f8df42fefb9"}}},{"cell_type":"code","source":["# from snowflake.snowpark import Session\n# import snowflake.snowpark.functions as F\n# import snowflake.snowpark.types as T\nfrom snowflake.snowpark.functions import to_date, datediff, max, min, countDistinct, count, sum, when\nfrom snowflake.snowpark.types import FloatType\n\ndisplay(Markdown(f''' \n**NOTE:** Changes made:\n - JOIN method\n - datediff function\n - agg\n - orderBy => sort\n'''))\n\n# valid customer orders\nx = orders.where(orders.CustomerID.isNotNull())\n\n# calculate last date in dataset\ny = (\n  orders\n    .groupBy()\n    .agg(max(to_date(orders.InvoiceDate)).alias('current_dt'))\n  )\n\n# calculate first transaction date by customer\nz = (\n  orders\n    .groupBy(orders.CustomerID)\n    .agg(min(to_date(orders.InvoiceDate)).alias('first_at'))\n  )\n\n\n# combine customer history with date info \na = (x\n    .crossJoin(y)\n    .join(z, x.CustomerID==z.CustomerID, join_type='inner')\n    .select(\n      x.CustomerID.alias('customerid'), \n      z.first_at, \n      F.to_date(x.InvoiceDate).alias('transaction_at'), \n      y.current_dt\n      )\n     .distinct()\n    )\n\n# calculate relevant metrics by customer\nmetrics_api = (a\n           .groupBy(a.customerid, a.current_dt, a.first_at)\n           .agg(\n             [(countDistinct(a.transaction_at)-1).cast(FloatType()).alias('frequency'),\n             datediff('day', max(a.transaction_at), a.first_at).cast(FloatType()).alias('recency'),\n             datediff('day', a.current_dt, a.first_at).cast(FloatType()).alias('T')\n             ]\n             )\n           .select('customerid','frequency','recency','T')\n           .sort('customerid')\n          )\ndisplay(metrics_api.limit(5).to_pandas())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c28adef2-743b-444f-a5eb-605820e741f9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n  CUSTOMERID  FREQUENCY  RECENCY      T\n0      12346        0.0      0.0 -325.0\n1      12347        6.0   -365.0 -367.0\n2      12348        3.0   -283.0 -358.0\n3      12349        0.0      0.0  -18.0\n4      12350        0.0      0.0 -310.0\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n  CUSTOMERID  FREQUENCY  RECENCY      T\n0      12346        0.0      0.0 -325.0\n1      12347        6.0   -365.0 -367.0\n2      12348        3.0   -283.0 -358.0\n3      12349        0.0      0.0  -18.0\n4      12350        0.0      0.0 -310.0\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Let's take a moment to compare the data in these different metrics datasets, just to confirm the results are identical.  Instead of doing this record by record, let's calculate summary statistics across each dataset to verify their consistency:\n\nNOTE You may notice means and standard deviations vary slightly in the hundred-thousandths and millionths decimal places.  This is a result of slight differences in data types between the pandas and Spark DataFrames but do not affect our results in a meaningful way."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fbde9bb6-70f7-41f6-a032-dd7f9fe60cdb"}}},{"cell_type":"code","source":["# summary data from lifetimes\nmetrics_pd.describe()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2421d97a-2fff-44f8-918a-48a70489b887"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frequency</th>\n      <th>recency</th>\n      <th>T</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4372.000000</td>\n      <td>4372.000000</td>\n      <td>4372.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.413541</td>\n      <td>133.723010</td>\n      <td>225.304209</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>6.674343</td>\n      <td>133.000474</td>\n      <td>118.384168</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>115.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>98.000000</td>\n      <td>253.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.000000</td>\n      <td>256.000000</td>\n      <td>331.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>145.000000</td>\n      <td>373.000000</td>\n      <td>373.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":"<div class=\"ansiout\">Out[7]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frequency</th>\n      <th>recency</th>\n      <th>T</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4372.000000</td>\n      <td>4372.000000</td>\n      <td>4372.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.413541</td>\n      <td>133.723010</td>\n      <td>225.304209</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>6.674343</td>\n      <td>133.000474</td>\n      <td>118.384168</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>115.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>98.000000</td>\n      <td>253.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.000000</td>\n      <td>256.000000</td>\n      <td>331.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>145.000000</td>\n      <td>373.000000</td>\n      <td>373.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# summary data from SQL statement\nmetrics_sql.toPandas().describe()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"417fac30-4d05-4db4-9715-e063e5047423"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[14]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[14]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FREQUENCY</th>\n      <th>RECENCY</th>\n      <th>T</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4372.000000</td>\n      <td>4372.000000</td>\n      <td>4372.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.413541</td>\n      <td>-133.723010</td>\n      <td>-225.304209</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>6.674343</td>\n      <td>133.000474</td>\n      <td>118.384168</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-373.000000</td>\n      <td>-373.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>-256.000000</td>\n      <td>-331.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>-98.000000</td>\n      <td>-253.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.000000</td>\n      <td>0.000000</td>\n      <td>-115.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>145.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FREQUENCY</th>\n      <th>RECENCY</th>\n      <th>T</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4372.000000</td>\n      <td>4372.000000</td>\n      <td>4372.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.413541</td>\n      <td>-133.723010</td>\n      <td>-225.304209</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>6.674343</td>\n      <td>133.000474</td>\n      <td>118.384168</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-373.000000</td>\n      <td>-373.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>-256.000000</td>\n      <td>-331.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>-98.000000</td>\n      <td>-253.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.000000</td>\n      <td>0.000000</td>\n      <td>-115.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>145.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# summary data from pyspark.sql API\nmetrics_api.toPandas().describe()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cc522090-787f-4f91-9742-b0aa98c070be"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frequency</th>\n      <th>recency</th>\n      <th>T</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4372.000000</td>\n      <td>4372.000000</td>\n      <td>4372.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.413541</td>\n      <td>133.723007</td>\n      <td>225.304214</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>6.674344</td>\n      <td>133.000473</td>\n      <td>118.384171</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>115.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>98.000000</td>\n      <td>253.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.000000</td>\n      <td>256.000000</td>\n      <td>331.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>145.000000</td>\n      <td>373.000000</td>\n      <td>373.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":"<div class=\"ansiout\">Out[9]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frequency</th>\n      <th>recency</th>\n      <th>T</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4372.000000</td>\n      <td>4372.000000</td>\n      <td>4372.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.413541</td>\n      <td>133.723007</td>\n      <td>225.304214</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>6.674344</td>\n      <td>133.000473</td>\n      <td>118.384171</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>115.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>98.000000</td>\n      <td>253.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.000000</td>\n      <td>256.000000</td>\n      <td>331.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>145.000000</td>\n      <td>373.000000</td>\n      <td>373.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["The metrics we've calculated represent summaries of a time series of data.  To support model validation and avoid overfitting, a common pattern with time series data is to train models on an earlier portion of the time series (known as the *calibration* period) and validate against a later portion of the time series (known as the *holdout* period). In the lifetimes library, the derivation of per customer metrics using calibration and holdout periods is done through a simple method call.  Because our dataset consists of a limited range for data, we will instruct this library method to use the last 90-days of data as the holdout period.  A simple parameter called a widget on the Databricks platform has been implemented to make the configuration of this setting easily changeable:\n\nNOTE To change the number of days in the holdout period, look for the textbox widget by scrolling to the top of your Databricks notebook after running this next cell"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2977b47f-f453-479b-8dc8-d0983d54bcd7"}}},{"cell_type":"code","source":["!pip install lifetimes==0.10.1"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5750e19c-a008-4d61-a033-03d721e9fdb7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Collecting lifetimes==0.10.1\r\n  Downloading Lifetimes-0.10.1-py3-none-any.whl (581 kB)\r\n\r     |▋                               | 10 kB 30.3 MB/s eta 0:00:01\r     |█▏                              | 20 kB 30.6 MB/s eta 0:00:01\r     |█▊                              | 30 kB 20.3 MB/s eta 0:00:01\r     |██▎                             | 40 kB 11.8 MB/s eta 0:00:01\r     |██▉                             | 51 kB 11.1 MB/s eta 0:00:01\r     |███▍                            | 61 kB 13.0 MB/s eta 0:00:01\r     |████                            | 71 kB 13.1 MB/s eta 0:00:01\r     |████▌                           | 81 kB 12.5 MB/s eta 0:00:01\r     |█████                           | 92 kB 13.9 MB/s eta 0:00:01\r     |█████▋                          | 102 kB 12.2 MB/s eta 0:00:01\r     |██████▏                         | 112 kB 12.2 MB/s eta 0:00:01\r     |██████▊                         | 122 kB 12.2 MB/s eta 0:00:01\r     |███████▎                        | 133 kB 12.2 MB/s eta 0:00:01\r     |███████▉                        | 143 kB 12.2 MB/s eta 0:00:01\r     |████████▌                       | 153 kB 12.2 MB/s eta 0:00:01\r     |█████████                       | 163 kB 12.2 MB/s eta 0:00:01\r     |█████████▋                      | 174 kB 12.2 MB/s eta 0:00:01\r     |██████████▏                     | 184 kB 12.2 MB/s eta 0:00:01\r     |██████████▊                     | 194 kB 12.2 MB/s eta 0:00:01\r     |███████████▎                    | 204 kB 12.2 MB/s eta 0:00:01\r     |███████████▉                    | 215 kB 12.2 MB/s eta 0:00:01\r     |████████████▍                   | 225 kB 12.2 MB/s eta 0:00:01\r     |█████████████                   | 235 kB 12.2 MB/s eta 0:00:01\r     |█████████████▌                  | 245 kB 12.2 MB/s eta 0:00:01\r     |██████████████                  | 256 kB 12.2 MB/s eta 0:00:01\r     |██████████████▋                 | 266 kB 12.2 MB/s eta 0:00:01\r     |███████████████▏                | 276 kB 12.2 MB/s eta 0:00:01\r     |███████████████▊                | 286 kB 12.2 MB/s eta 0:00:01\r     |████████████████▍               | 296 kB 12.2 MB/s eta 0:00:01\r     |█████████████████               | 307 kB 12.2 MB/s eta 0:00:01\r     |█████████████████▌              | 317 kB 12.2 MB/s eta 0:00:01\r     |██████████████████              | 327 kB 12.2 MB/s eta 0:00:01\r     |██████████████████▋             | 337 kB 12.2 MB/s eta 0:00:01\r     |███████████████████▏            | 348 kB 12.2 MB/s eta 0:00:01\r     |███████████████████▊            | 358 kB 12.2 MB/s eta 0:00:01\r     |████████████████████▎           | 368 kB 12.2 MB/s eta 0:00:01\r     |████████████████████▉           | 378 kB 12.2 MB/s eta 0:00:01\r     |█████████████████████▍          | 389 kB 12.2 MB/s eta 0:00:01\r     |██████████████████████          | 399 kB 12.2 MB/s eta 0:00:01\r     |██████████████████████▌         | 409 kB 12.2 MB/s eta 0:00:01\r     |███████████████████████         | 419 kB 12.2 MB/s eta 0:00:01\r     |███████████████████████▋        | 430 kB 12.2 MB/s eta 0:00:01\r     |████████████████████████▎       | 440 kB 12.2 MB/s eta 0:00:01\r     |████████████████████████▉       | 450 kB 12.2 MB/s eta 0:00:01\r     |█████████████████████████▍      | 460 kB 12.2 MB/s eta 0:00:01\r     |██████████████████████████      | 471 kB 12.2 MB/s eta 0:00:01\r     |██████████████████████████▌     | 481 kB 12.2 MB/s eta 0:00:01\r     |███████████████████████████     | 491 kB 12.2 MB/s eta 0:00:01\r     |███████████████████████████▋    | 501 kB 12.2 MB/s eta 0:00:01\r     |████████████████████████████▏   | 512 kB 12.2 MB/s eta 0:00:01\r     |████████████████████████████▊   | 522 kB 12.2 MB/s eta 0:00:01\r     |█████████████████████████████▎  | 532 kB 12.2 MB/s eta 0:00:01\r     |█████████████████████████████▉  | 542 kB 12.2 MB/s eta 0:00:01\r     |██████████████████████████████▍ | 552 kB 12.2 MB/s eta 0:00:01\r     |███████████████████████████████ | 563 kB 12.2 MB/s eta 0:00:01\r     |███████████████████████████████▌| 573 kB 12.2 MB/s eta 0:00:01\r     |████████████████████████████████| 581 kB 12.2 MB/s \r\nRequirement already satisfied: pandas&gt;=0.19 in /databricks/python3/lib/python3.8/site-packages (from lifetimes==0.10.1) (1.2.4)\r\nCollecting dill&gt;=0.2.6\r\n  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\r\n\r     |███▊                            | 10 kB 48.5 MB/s eta 0:00:01\r     |███████▌                        | 20 kB 57.7 MB/s eta 0:00:01\r     |███████████▎                    | 30 kB 69.3 MB/s eta 0:00:01\r     |███████████████                 | 40 kB 76.9 MB/s eta 0:00:01\r     |██████████████████▉             | 51 kB 81.7 MB/s eta 0:00:01\r     |██████████████████████▋         | 61 kB 87.8 MB/s eta 0:00:01\r     |██████████████████████████▍     | 71 kB 91.2 MB/s eta 0:00:01\r     |██████████████████████████████▏ | 81 kB 94.2 MB/s eta 0:00:01\r     |████████████████████████████████| 86 kB 6.6 MB/s \r\nRequirement already satisfied: scipy&gt;=1.0.0 in /databricks/python3/lib/python3.8/site-packages (from lifetimes==0.10.1) (1.6.2)\r\nRequirement already satisfied: numpy&gt;=1.10.0 in /databricks/python3/lib/python3.8/site-packages (from lifetimes==0.10.1) (1.20.1)\r\nRequirement already satisfied: pytz&gt;=2017.3 in /databricks/python3/lib/python3.8/site-packages (from pandas&gt;=0.19-&gt;lifetimes==0.10.1) (2020.5)\r\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from pandas&gt;=0.19-&gt;lifetimes==0.10.1) (2.8.1)\r\nRequirement already satisfied: six&gt;=1.5 in /databricks/python3/lib/python3.8/site-packages (from python-dateutil&gt;=2.7.3-&gt;pandas&gt;=0.19-&gt;lifetimes==0.10.1) (1.15.0)\r\nInstalling collected packages: dill, lifetimes\r\nSuccessfully installed dill-0.3.4 lifetimes-0.10.1\r\n<span class=\"ansi-yellow-fg\">WARNING: You are using pip version 21.0.1; however, version 22.1 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Collecting lifetimes==0.10.1\r\n  Downloading Lifetimes-0.10.1-py3-none-any.whl (581 kB)\r\n▋                               | 10 kB 30.3 MB/s eta 0:00:01\r     |█▏                              | 20 kB 30.6 MB/s eta 0:00:01\r     |█▊                              | 30 kB 20.3 MB/s eta 0:00:01\r     |██▎                             | 40 kB 11.8 MB/s eta 0:00:01\r     |██▉                             | 51 kB 11.1 MB/s eta 0:00:01\r     |███▍                            | 61 kB 13.0 MB/s eta 0:00:01\r     |████                            | 71 kB 13.1 MB/s eta 0:00:01\r     |████▌                           | 81 kB 12.5 MB/s eta 0:00:01\r     |█████                           | 92 kB 13.9 MB/s eta 0:00:01\r     |█████▋                          | 102 kB 12.2 MB/s eta 0:00:01\r     |██████▏                         | 112 kB 12.2 MB/s eta 0:00:01\r     |██████▊                         | 122 kB 12.2 MB/s eta 0:00:01\r     |███████▎                        | 133 kB 12.2 MB/s eta 0:00:01\r     |███████▉                        | 143 kB 12.2 MB/s eta 0:00:01\r     |████████▌                       | 153 kB 12.2 MB/s eta 0:00:01\r     |█████████                       | 163 kB 12.2 MB/s eta 0:00:01\r     |█████████▋                      | 174 kB 12.2 MB/s eta 0:00:01\r     |██████████▏                     | 184 kB 12.2 MB/s eta 0:00:01\r     |██████████▊                     | 194 kB 12.2 MB/s eta 0:00:01\r     |███████████▎                    | 204 kB 12.2 MB/s eta 0:00:01\r     |███████████▉                    | 215 kB 12.2 MB/s eta 0:00:01\r     |████████████▍                   | 225 kB 12.2 MB/s eta 0:00:01\r     |█████████████                   | 235 kB 12.2 MB/s eta 0:00:01\r     |█████████████▌                  | 245 kB 12.2 MB/s eta 0:00:01\r     |██████████████                  | 256 kB 12.2 MB/s eta 0:00:01\r     |██████████████▋                 | 266 kB 12.2 MB/s eta 0:00:01\r     |███████████████▏                | 276 kB 12.2 MB/s eta 0:00:01\r     |███████████████▊                | 286 kB 12.2 MB/s eta 0:00:01\r     |████████████████▍               | 296 kB 12.2 MB/s eta 0:00:01\r     |█████████████████               | 307 kB 12.2 MB/s eta 0:00:01\r     |█████████████████▌              | 317 kB 12.2 MB/s eta 0:00:01\r     |██████████████████              | 327 kB 12.2 MB/s eta 0:00:01\r     |██████████████████▋             | 337 kB 12.2 MB/s eta 0:00:01\r     |███████████████████▏            | 348 kB 12.2 MB/s eta 0:00:01\r     |███████████████████▊            | 358 kB 12.2 MB/s eta 0:00:01\r     |████████████████████▎           | 368 kB 12.2 MB/s eta 0:00:01\r     |████████████████████▉           | 378 kB 12.2 MB/s eta 0:00:01\r     |█████████████████████▍          | 389 kB 12.2 MB/s eta 0:00:01\r     |██████████████████████          | 399 kB 12.2 MB/s eta 0:00:01\r     |██████████████████████▌         | 409 kB 12.2 MB/s eta 0:00:01\r     |███████████████████████         | 419 kB 12.2 MB/s eta 0:00:01\r     |███████████████████████▋        | 430 kB 12.2 MB/s eta 0:00:01\r     |████████████████████████▎       | 440 kB 12.2 MB/s eta 0:00:01\r     |████████████████████████▉       | 450 kB 12.2 MB/s eta 0:00:01\r     |█████████████████████████▍      | 460 kB 12.2 MB/s eta 0:00:01\r     |██████████████████████████      | 471 kB 12.2 MB/s eta 0:00:01\r     |██████████████████████████▌     | 481 kB 12.2 MB/s eta 0:00:01\r     |███████████████████████████     | 491 kB 12.2 MB/s eta 0:00:01\r     |███████████████████████████▋    | 501 kB 12.2 MB/s eta 0:00:01\r     |████████████████████████████▏   | 512 kB 12.2 MB/s eta 0:00:01\r     |████████████████████████████▊   | 522 kB 12.2 MB/s eta 0:00:01\r     |█████████████████████████████▎  | 532 kB 12.2 MB/s eta 0:00:01\r     |█████████████████████████████▉  | 542 kB 12.2 MB/s eta 0:00:01\r     |██████████████████████████████▍ | 552 kB 12.2 MB/s eta 0:00:01\r     |███████████████████████████████ | 563 kB 12.2 MB/s eta 0:00:01\r     |███████████████████████████████▌| 573 kB 12.2 MB/s eta 0:00:01\r     |████████████████████████████████| 581 kB 12.2 MB/s \r\nRequirement already satisfied: pandas&gt;=0.19 in /databricks/python3/lib/python3.8/site-packages (from lifetimes==0.10.1) (1.2.4)\r\nCollecting dill&gt;=0.2.6\r\n  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\r\n███▊                            | 10 kB 48.5 MB/s eta 0:00:01\r     |███████▌                        | 20 kB 57.7 MB/s eta 0:00:01\r     |███████████▎                    | 30 kB 69.3 MB/s eta 0:00:01\r     |███████████████                 | 40 kB 76.9 MB/s eta 0:00:01\r     |██████████████████▉             | 51 kB 81.7 MB/s eta 0:00:01\r     |██████████████████████▋         | 61 kB 87.8 MB/s eta 0:00:01\r     |██████████████████████████▍     | 71 kB 91.2 MB/s eta 0:00:01\r     |██████████████████████████████▏ | 81 kB 94.2 MB/s eta 0:00:01\r     |████████████████████████████████| 86 kB 6.6 MB/s \r\nRequirement already satisfied: scipy&gt;=1.0.0 in /databricks/python3/lib/python3.8/site-packages (from lifetimes==0.10.1) (1.6.2)\r\nRequirement already satisfied: numpy&gt;=1.10.0 in /databricks/python3/lib/python3.8/site-packages (from lifetimes==0.10.1) (1.20.1)\r\nRequirement already satisfied: pytz&gt;=2017.3 in /databricks/python3/lib/python3.8/site-packages (from pandas&gt;=0.19-&gt;lifetimes==0.10.1) (2020.5)\r\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from pandas&gt;=0.19-&gt;lifetimes==0.10.1) (2.8.1)\r\nRequirement already satisfied: six&gt;=1.5 in /databricks/python3/lib/python3.8/site-packages (from python-dateutil&gt;=2.7.3-&gt;pandas&gt;=0.19-&gt;lifetimes==0.10.1) (1.15.0)\r\nInstalling collected packages: dill, lifetimes\r\nSuccessfully installed dill-0.3.4 lifetimes-0.10.1\r\n<span class=\"ansi-yellow-fg\">WARNING: You are using pip version 21.0.1; however, version 22.1 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from datetime import timedelta\nfrom snowflake.snowpark.functions import lit\nimport lifetimes\n\n# set the last transaction date as the end point for this historical dataset\ncurrent_date = orders_pd['InvoiceDate'].max()\n\n# define end of calibration period\n# holdout_days = int(dbutils.widgets.get('holdout days'))\nholdout_days=90\ncalibration_end_date = current_date - timedelta(days = holdout_days )\n\n# calculate the required customer metrics\nmetrics_cal_pd = (\n  lifetimes.utils.calibration_and_holdout_data(\n    orders_pd,\n    customer_id_col='CustomerID',\n    datetime_col='InvoiceDate',\n    observation_period_end = current_date,\n    calibration_period_end=calibration_end_date,\n    freq='D'    \n    )\n  )\n\n# display first few rows\nmetrics_cal_pd.head(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7bac2c03-d397-4b93-8f2f-d417bc0103c5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[20]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[20]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frequency_cal</th>\n      <th>recency_cal</th>\n      <th>T_cal</th>\n      <th>frequency_holdout</th>\n      <th>duration_holdout</th>\n    </tr>\n    <tr>\n      <th>CustomerID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12346</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>235.0</td>\n      <td>0.0</td>\n      <td>&lt;90 * Days&gt;</td>\n    </tr>\n    <tr>\n      <th>12347</th>\n      <td>4.0</td>\n      <td>238.0</td>\n      <td>277.0</td>\n      <td>2.0</td>\n      <td>&lt;90 * Days&gt;</td>\n    </tr>\n    <tr>\n      <th>12348</th>\n      <td>2.0</td>\n      <td>110.0</td>\n      <td>268.0</td>\n      <td>1.0</td>\n      <td>&lt;90 * Days&gt;</td>\n    </tr>\n    <tr>\n      <th>12350</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>220.0</td>\n      <td>0.0</td>\n      <td>&lt;90 * Days&gt;</td>\n    </tr>\n    <tr>\n      <th>12352</th>\n      <td>3.0</td>\n      <td>34.0</td>\n      <td>206.0</td>\n      <td>3.0</td>\n      <td>&lt;90 * Days&gt;</td>\n    </tr>\n    <tr>\n      <th>12353</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>114.0</td>\n      <td>0.0</td>\n      <td>&lt;90 * Days&gt;</td>\n    </tr>\n    <tr>\n      <th>12354</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>142.0</td>\n      <td>0.0</td>\n      <td>&lt;90 * Days&gt;</td>\n    </tr>\n    <tr>\n      <th>12355</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>124.0</td>\n      <td>0.0</td>\n      <td>&lt;90 * Days&gt;</td>\n    </tr>\n    <tr>\n      <th>12356</th>\n      <td>1.0</td>\n      <td>80.0</td>\n      <td>235.0</td>\n      <td>1.0</td>\n      <td>&lt;90 * Days&gt;</td>\n    </tr>\n    <tr>\n      <th>12358</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>&lt;90 * Days&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frequency_cal</th>\n      <th>recency_cal</th>\n      <th>T_cal</th>\n      <th>frequency_holdout</th>\n      <th>duration_holdout</th>\n    </tr>\n    <tr>\n      <th>CustomerID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12346</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>235.0</td>\n      <td>0.0</td>\n      <td>&lt;90 * Days&gt;</td>\n    </tr>\n    <tr>\n      <th>12347</th>\n      <td>4.0</td>\n      <td>238.0</td>\n      <td>277.0</td>\n      <td>2.0</td>\n      <td>&lt;90 * Days&gt;</td>\n    </tr>\n    <tr>\n      <th>12348</th>\n      <td>2.0</td>\n      <td>110.0</td>\n      <td>268.0</td>\n      <td>1.0</td>\n      <td>&lt;90 * Days&gt;</td>\n    </tr>\n    <tr>\n      <th>12350</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>220.0</td>\n      <td>0.0</td>\n      <td>&lt;90 * Days&gt;</td>\n    </tr>\n    <tr>\n      <th>12352</th>\n      <td>3.0</td>\n      <td>34.0</td>\n      <td>206.0</td>\n      <td>3.0</td>\n      <td>&lt;90 * Days&gt;</td>\n    </tr>\n    <tr>\n      <th>12353</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>114.0</td>\n      <td>0.0</td>\n      <td>&lt;90 * Days&gt;</td>\n    </tr>\n    <tr>\n      <th>12354</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>142.0</td>\n      <td>0.0</td>\n      <td>&lt;90 * Days&gt;</td>\n    </tr>\n    <tr>\n      <th>12355</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>124.0</td>\n      <td>0.0</td>\n      <td>&lt;90 * Days&gt;</td>\n    </tr>\n    <tr>\n      <th>12356</th>\n      <td>1.0</td>\n      <td>80.0</td>\n      <td>235.0</td>\n      <td>1.0</td>\n      <td>&lt;90 * Days&gt;</td>\n    </tr>\n    <tr>\n      <th>12358</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>&lt;90 * Days&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["As before, we may leverage Spark SQL to derive this same information.  Again, we'll examine this through both a SQL statement and the programmatic SQL API.\n\nTo understand the SQL statement, first recognize that it's divided into two main parts.  In the first, we calculate the core metrics, *i.e.* recency, frequency and age (T), per customer for the calibration period, much like we did in the previous query example. In the second part of the query, we calculate the number of purchase dates in the holdout customer for each customer.  This value (frequency_holdout) represents the incremental value to be added to the frequency for the calibration period (frequency_cal) when we examine a customer's entire transaction history across both calibration and holdout periods.\n\nTo simplify our logic, a common table expression (CTE) named CustomerHistory is defined at the top of the query.  This query extracts the relevant dates that make up a customer's transaction history and closely mirrors the logic at the center of the last SQL statement we examined.  The only difference is that we include the number of days in the holdout period (duration_holdout):"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"167a3f4d-b072-4db9-a86a-297d4800f747"}}},{"cell_type":"code","source":["\ndisplay(Markdown(f''' \n**NOTE:** Changes made:\n - getArgument is replaced with formatted string\n'''))\n\n# vsql = f'''\n# WITH CustomerHistory \n#   AS (\n#     SELECT  -- nesting req'ed b/c can't SELECT DISTINCT on widget parameter\n#       m.*,\n#       cast(getArgument('holdout days') as int) as duration_holdout\n#     FROM (\n#       SELECT DISTINCT\n#         x.customerid,\n#         z.first_at,\n#         TO_DATE(x.invoicedate) as transaction_at,\n#         y.current_dt\n#       FROM orders x\n#       CROSS JOIN (SELECT MAX(TO_DATE(invoicedate)) as current_dt FROM orders) y                                -- current date (according to dataset)\n#       INNER JOIN (SELECT customerid, MIN(TO_DATE(invoicedate)) as first_at FROM orders GROUP BY customerid) z  -- first order per customer\n#         ON x.customerid=z.customerid\n#       WHERE x.customerid IS NOT NULL\n#     ) m\n#   )\n#        SELECT\n#         *\n#     FROM CustomerHistory p\n# '''\n\nvsql = f'''\nWITH CustomerHistory \n  AS (\n    SELECT  -- nesting req'ed b/c can't SELECT DISTINCT on widget parameter\n      m.*,\n      cast({holdout_days} as int) as duration_holdout\n    FROM (\n      SELECT DISTINCT\n        x.customerid,\n        z.first_at,\n        TO_DATE(x.invoicedate) as transaction_at,\n        y.current_dt\n      FROM orders x\n      CROSS JOIN (SELECT MAX(TO_DATE(invoicedate)) as current_dt FROM orders) y                                -- current date (according to dataset)\n      INNER JOIN (SELECT customerid, MIN(TO_DATE(invoicedate)) as first_at FROM orders GROUP BY customerid) z  -- first order per customer\n        ON x.customerid=z.customerid\n      WHERE x.customerid IS NOT NULL\n    ) m\n  )\n       SELECT\n        *\n    FROM CustomerHistory p\n'''\n\n# vsql_df = spark.sql(vsql)\n# display(vsql_df)\n\nvsql_df = session.sql(vsql)\ndisplay(vsql_df.limit(5).to_pandas())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e7cb5057-8d32-4ac1-8034-1f96c8798591"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n  CUSTOMERID    FIRST_AT TRANSACTION_AT  CURRENT_DT  DURATION_HOLDOUT\n0      17850  2010-12-01     2010-12-01  2011-12-09                90\n1      13047  2010-12-01     2010-12-01  2011-12-09                90\n2      12583  2010-12-01     2010-12-01  2011-12-09                90\n3      13748  2010-12-01     2010-12-01  2011-12-09                90\n4      15100  2010-12-01     2010-12-01  2011-12-09                90\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n  CUSTOMERID    FIRST_AT TRANSACTION_AT  CURRENT_DT  DURATION_HOLDOUT\n0      17850  2010-12-01     2010-12-01  2011-12-09                90\n1      13047  2010-12-01     2010-12-01  2011-12-09                90\n2      12583  2010-12-01     2010-12-01  2011-12-09                90\n3      13748  2010-12-01     2010-12-01  2011-12-09                90\n4      15100  2010-12-01     2010-12-01  2011-12-09                90\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["\n# sql = '''\n# WITH CustomerHistory \n#   AS (\n#     SELECT  -- nesting req'ed b/c can't SELECT DISTINCT on widget parameter\n#       m.*,\n#       -- getArgument('holdout days') as duration_holdout -- <== updated by venkat\n#       cast(getArgument('holdout days') as int) as duration_holdout -- <== updated by venkat\n#     FROM (\n#       SELECT DISTINCT\n#         x.customerid,\n#         z.first_at,\n#         TO_DATE(x.invoicedate) as transaction_at,\n#         y.current_dt\n#       FROM orders x\n#       CROSS JOIN (SELECT MAX(TO_DATE(invoicedate)) as current_dt FROM orders) y                                -- current date (according to dataset)\n#       INNER JOIN (SELECT customerid, MIN(TO_DATE(invoicedate)) as first_at FROM orders GROUP BY customerid) z  -- first order per customer\n#         ON x.customerid=z.customerid\n#       WHERE x.customerid IS NOT NULL\n#     ) m\n#   )\n# SELECT\n#     a.customerid as CustomerID,\n#     a.frequency as frequency_cal,\n#     a.recency as recency_cal,\n#     a.T as T_cal,\n#     COALESCE(b.frequency_holdout, 0.0) as frequency_holdout,\n#     a.duration_holdout\n# FROM ( -- CALIBRATION PERIOD CALCULATIONS\n#     SELECT\n#         p.customerid,\n#         CAST(p.duration_holdout as float) as duration_holdout,\n#         CAST(DATEDIFF(MAX(p.transaction_at), p.first_at) as float) as recency,\n#         CAST(COUNT(DISTINCT p.transaction_at) - 1 as float) as frequency,\n#         CAST(DATEDIFF(DATE_SUB(p.current_dt, p.duration_holdout), p.first_at) as float) as T\n#     FROM CustomerHistory p\n#     WHERE p.transaction_at < DATE_SUB(p.current_dt, p.duration_holdout)  -- LIMIT THIS QUERY TO DATA IN THE CALIBRATION PERIOD\n#     GROUP BY p.customerid, p.first_at, p.current_dt, p.duration_holdout\n#   ) a\n# LEFT OUTER JOIN ( -- HOLDOUT PERIOD CALCULATIONS\n#   SELECT\n#     p.customerid,\n#     CAST(COUNT(DISTINCT p.transaction_at) as float) as frequency_holdout\n#   FROM CustomerHistory p\n#   WHERE \n#     p.transaction_at >= DATE_SUB(p.current_dt, p.duration_holdout) AND  -- LIMIT THIS QUERY TO DATA IN THE HOLDOUT PERIOD\n#     p.transaction_at <= p.current_dt\n#   GROUP BY p.customerid\n#   ) b\n#   ON a.customerid=b.customerid\n# ORDER BY CustomerID\n# '''\n\ndisplay(Markdown(f''' \n**NOTE:** Changes made:\n - DATE_SUB replaced with dateadd\n'''))\n\nsql = f'''\nWITH CustomerHistory \n  AS (\n    SELECT  -- nesting req'ed b/c can't SELECT DISTINCT on widget parameter\n      m.*,\n      cast({holdout_days} as int) as duration_holdout\n    FROM (\n      SELECT DISTINCT\n        x.customerid,\n        z.first_at,\n        TO_DATE(x.invoicedate) as transaction_at,\n        y.current_dt\n      FROM orders x\n      CROSS JOIN (SELECT MAX(TO_DATE(invoicedate)) as current_dt FROM orders) y                                -- current date (according to dataset)\n      INNER JOIN (SELECT customerid, MIN(TO_DATE(invoicedate)) as first_at FROM orders GROUP BY customerid) z  -- first order per customer\n        ON x.customerid=z.customerid\n      WHERE x.customerid IS NOT NULL\n    ) m\n  )\n\n SELECT\n     a.customerid as CustomerID,\n     a.frequency as frequency_cal,\n     a.recency as recency_cal,\n     a.T as T_cal,\n     COALESCE(b.frequency_holdout, 0.0) as frequency_holdout,\n     a.duration_holdout\n FROM ( -- CALIBRATION PERIOD CALCULATIONS\n     SELECT\n         p.customerid,\n         CAST(p.duration_holdout as float) as duration_holdout,\n         CAST(DATEDIFF( 'day', MAX(p.transaction_at), p.first_at) as float) as recency,\n         CAST(COUNT(DISTINCT p.transaction_at) - 1 as float) as frequency,\n         CAST(DATEDIFF( 'day'\n            ,DATEADD( 'day', -1 * p.duration_holdout, p.current_dt ) \n            ,p.first_at) as float) as T\n     FROM CustomerHistory p\n     WHERE p.transaction_at < DATEADD( 'day', -1 * p.duration_holdout, p.current_dt )   -- LIMIT THIS QUERY TO DATA IN THE CALIBRATION PERIOD\n     GROUP BY p.customerid, p.first_at, p.current_dt, p.duration_holdout\n   ) a\n\nLEFT OUTER JOIN ( -- HOLDOUT PERIOD CALCULATIONS\n  SELECT\n    p.customerid,\n    CAST(COUNT(DISTINCT p.transaction_at) as float) as frequency_holdout\n  FROM CustomerHistory p\n  WHERE \n    p.transaction_at >= DATEADD( 'day', -1 * p.duration_holdout, p.current_dt )  AND  -- LIMIT THIS QUERY TO DATA IN THE HOLDOUT PERIOD\n    p.transaction_at <= p.current_dt\n  GROUP BY p.customerid\n  ) b\n  ON a.customerid=b.customerid\nORDER BY CustomerID\n  \n'''\n\n# metrics_cal_sql = spark.sql(sql)\n# display(metrics_cal_sql)\n\nmetrics_cal_sql = session.sql(sql)\ndisplay(metrics_cal_sql.limit(5).to_pandas())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"51166008-a39b-45e2-8738-a9c3807fdb1c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n  CUSTOMERID  FREQUENCY_CAL  ...  FREQUENCY_HOLDOUT  DURATION_HOLDOUT\n0      12346            0.0  ...                0.0              90.0\n1      12347            4.0  ...                2.0              90.0\n2      12348            2.0  ...                1.0              90.0\n3      12350            0.0  ...                0.0              90.0\n4      12352            3.0  ...                3.0              90.0\n\n[5 rows x 6 columns]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n  CUSTOMERID  FREQUENCY_CAL  ...  FREQUENCY_HOLDOUT  DURATION_HOLDOUT\n0      12346            0.0  ...                0.0              90.0\n1      12347            4.0  ...                2.0              90.0\n2      12348            2.0  ...                1.0              90.0\n3      12350            0.0  ...                0.0              90.0\n4      12352            3.0  ...                3.0              90.0\n\n[5 rows x 6 columns]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["And here is the equivalent Programmatic SQL API logic:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"35b7734b-3f98-47ef-9f19-1ccfc9206ce0"}}},{"cell_type":"code","source":["from snowflake.snowpark.functions import avg, dateadd, coalesce, lit ,col #, expr\n# from snowflake.snowpark.types import FloatType\n\ndisplay(Markdown(f''' \n**NOTE:** Changes made:\n - join method\n'''))\n\n# valid customer orders\nx = orders.where(orders.CustomerID.isNotNull())\n\n# calculate last date in dataset\ny = (\n  orders\n    .groupBy()\n    .agg(max(to_date(orders.InvoiceDate)).alias('current_dt'))\n  )\n\n# calculate first transaction date by customer\nz = (\n  orders\n    .groupBy(orders.CustomerID)\n    .agg(min(to_date(orders.InvoiceDate)).alias('first_at'))\n  )\n\n# combine customer history with date info (CUSTOMER HISTORY)\np = (x\n    .crossJoin(y)\n    .join(z, x.CustomerID==z.CustomerID, join_type='inner')\n    .withColumn('duration_holdout', lit(int(holdout_days)))\n    .select(\n      x.CustomerID.alias('customerid'),\n      z.first_at, \n      to_date(x.InvoiceDate).alias('transaction_at'), \n      y.current_dt, \n      'duration_holdout'\n      )\n     .distinct()\n    )\n\n# calculate relevant metrics by customer\n# note: date_sub requires a single integer value unless employed within an expr() call\na = (p\n       #.where(p.transaction_at < expr('date_sub(current_dt, duration_holdout)')) \n       .where(p.transaction_at < dateadd('day', -1 * col('duration_holdout') ,col('current_dt')  ))   \n       .groupBy(p.customerid, p.current_dt, p.duration_holdout, p.first_at)\n       .agg( [\n         (countDistinct(p.transaction_at)-1).cast(FloatType()).alias('frequency_cal'),\n         #datediff( max(p.transaction_at), p.first_at).cast(FloatType()).alias('recency_cal'),\n         datediff( 'day', max(p.transaction_at), p.first_at).cast(FloatType()).alias('recency_cal'),\n         #datediff( expr('date_sub(current_dt, duration_holdout)'), p.first_at).cast(FloatType()).alias('T_cal')\n         datediff( 'day'\n             #expr('date_sub(current_dt, duration_holdout)')\n             ,dateadd('day',  -1 * col('duration_holdout') ,col('current_dt')  )\n             ,p.first_at).cast(FloatType()).alias('T_cal')\n       ])\n    )\n\nb = (p\n      #.where((p.transaction_at >= expr('date_sub(current_dt, duration_holdout)')) & (p.transaction_at <= p.current_dt) )\n      .where((p.transaction_at >=  dateadd('day',  -1 * col('duration_holdout') ,col('current_dt')  ) ) & (p.transaction_at <= p.current_dt) )\n      .groupBy(p.customerid)\n      .agg(\n        countDistinct(p.transaction_at).cast(FloatType()).alias('frequency_holdout')\n        )\n   )\n\nmetrics_cal_api = (a\n                 .join(b, a.customerid==b.customerid, join_type='left')\n                 .select(\n                   a.customerid.alias('CustomerID'),\n                   a.frequency_cal,\n                   a.recency_cal,\n                   a.T_cal,\n                   coalesce(b.frequency_holdout, lit(0.0)).alias('frequency_holdout'),\n                   a.duration_holdout\n                   )\n                 .sort('CustomerID')\n              )\n\n#display(metrics_cal_api)\ndisplay(metrics_cal_api.limit(5).to_pandas())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"403a18c0-4126-4f7f-98dd-a9a35e58ad0d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n  CUSTOMERID  FREQUENCY_CAL  ...  FREQUENCY_HOLDOUT  DURATION_HOLDOUT\n0      12346            0.0  ...                0.0                90\n1      12347            4.0  ...                2.0                90\n2      12348            2.0  ...                1.0                90\n3      12350            0.0  ...                0.0                90\n4      12352            3.0  ...                3.0                90\n\n[5 rows x 6 columns]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;IPython.core.display.Markdown object&gt;\n  CUSTOMERID  FREQUENCY_CAL  ...  FREQUENCY_HOLDOUT  DURATION_HOLDOUT\n0      12346            0.0  ...                0.0                90\n1      12347            4.0  ...                2.0                90\n2      12348            2.0  ...                1.0                90\n3      12350            0.0  ...                0.0                90\n4      12352            3.0  ...                3.0                90\n\n[5 rows x 6 columns]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Using summary stats, we can again verify these different units of logic are returning the same results:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"94cc2fb1-58ce-4ec3-8f17-27d5e8d214d9"}}},{"cell_type":"code","source":["# summary data from lifetimes\nmetrics_cal_pd.describe()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aa34c222-f6b4-44d3-929b-127c7d63e376"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[27]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[27]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frequency_cal</th>\n      <th>recency_cal</th>\n      <th>T_cal</th>\n      <th>frequency_holdout</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3412.000000</td>\n      <td>3412.000000</td>\n      <td>3412.000000</td>\n      <td>3412.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.677608</td>\n      <td>90.587046</td>\n      <td>185.041618</td>\n      <td>1.502345</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.222838</td>\n      <td>96.077761</td>\n      <td>80.771943</td>\n      <td>2.495318</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>125.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>59.500000</td>\n      <td>197.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.000000</td>\n      <td>175.000000</td>\n      <td>268.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>93.000000</td>\n      <td>282.000000</td>\n      <td>283.000000</td>\n      <td>52.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frequency_cal</th>\n      <th>recency_cal</th>\n      <th>T_cal</th>\n      <th>frequency_holdout</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3412.000000</td>\n      <td>3412.000000</td>\n      <td>3412.000000</td>\n      <td>3412.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.677608</td>\n      <td>90.587046</td>\n      <td>185.041618</td>\n      <td>1.502345</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.222838</td>\n      <td>96.077761</td>\n      <td>80.771943</td>\n      <td>2.495318</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>125.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>59.500000</td>\n      <td>197.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.000000</td>\n      <td>175.000000</td>\n      <td>268.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>93.000000</td>\n      <td>282.000000</td>\n      <td>283.000000</td>\n      <td>52.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# summary data from SQL statement\nmetrics_cal_sql.toPandas().describe()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"688bbe46-5b52-4be7-9e3b-161ee9315f95"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[24]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[24]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FREQUENCY_CAL</th>\n      <th>RECENCY_CAL</th>\n      <th>T_CAL</th>\n      <th>FREQUENCY_HOLDOUT</th>\n      <th>DURATION_HOLDOUT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3412.000000</td>\n      <td>3412.000000</td>\n      <td>3412.000000</td>\n      <td>3412.000000</td>\n      <td>3412.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.677608</td>\n      <td>-90.587046</td>\n      <td>-185.041618</td>\n      <td>1.502345</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.222838</td>\n      <td>96.077761</td>\n      <td>80.771943</td>\n      <td>2.495318</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-282.000000</td>\n      <td>-283.000000</td>\n      <td>0.000000</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>-175.000000</td>\n      <td>-268.000000</td>\n      <td>0.000000</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>-59.500000</td>\n      <td>-197.000000</td>\n      <td>1.000000</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>-125.000000</td>\n      <td>2.000000</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>93.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>52.000000</td>\n      <td>90.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FREQUENCY_CAL</th>\n      <th>RECENCY_CAL</th>\n      <th>T_CAL</th>\n      <th>FREQUENCY_HOLDOUT</th>\n      <th>DURATION_HOLDOUT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3412.000000</td>\n      <td>3412.000000</td>\n      <td>3412.000000</td>\n      <td>3412.000000</td>\n      <td>3412.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.677608</td>\n      <td>-90.587046</td>\n      <td>-185.041618</td>\n      <td>1.502345</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.222838</td>\n      <td>96.077761</td>\n      <td>80.771943</td>\n      <td>2.495318</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-282.000000</td>\n      <td>-283.000000</td>\n      <td>0.000000</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>-175.000000</td>\n      <td>-268.000000</td>\n      <td>0.000000</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>-59.500000</td>\n      <td>-197.000000</td>\n      <td>1.000000</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>-125.000000</td>\n      <td>2.000000</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>93.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>52.000000</td>\n      <td>90.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# summary data from pyspark.sql API\nmetrics_cal_api.toPandas().describe()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3306d097-b5b1-4c0b-9e87-ae31a125c160"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[25]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[25]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FREQUENCY_CAL</th>\n      <th>RECENCY_CAL</th>\n      <th>T_CAL</th>\n      <th>FREQUENCY_HOLDOUT</th>\n      <th>DURATION_HOLDOUT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3412.000000</td>\n      <td>3412.000000</td>\n      <td>3412.000000</td>\n      <td>3412.000000</td>\n      <td>3412.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.677608</td>\n      <td>-90.587046</td>\n      <td>-185.041618</td>\n      <td>1.502345</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.222838</td>\n      <td>96.077761</td>\n      <td>80.771943</td>\n      <td>2.495318</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-282.000000</td>\n      <td>-283.000000</td>\n      <td>0.000000</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>-175.000000</td>\n      <td>-268.000000</td>\n      <td>0.000000</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>-59.500000</td>\n      <td>-197.000000</td>\n      <td>1.000000</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>-125.000000</td>\n      <td>2.000000</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>93.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>52.000000</td>\n      <td>90.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FREQUENCY_CAL</th>\n      <th>RECENCY_CAL</th>\n      <th>T_CAL</th>\n      <th>FREQUENCY_HOLDOUT</th>\n      <th>DURATION_HOLDOUT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3412.000000</td>\n      <td>3412.000000</td>\n      <td>3412.000000</td>\n      <td>3412.000000</td>\n      <td>3412.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.677608</td>\n      <td>-90.587046</td>\n      <td>-185.041618</td>\n      <td>1.502345</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.222838</td>\n      <td>96.077761</td>\n      <td>80.771943</td>\n      <td>2.495318</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-282.000000</td>\n      <td>-283.000000</td>\n      <td>0.000000</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>-175.000000</td>\n      <td>-268.000000</td>\n      <td>0.000000</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>-59.500000</td>\n      <td>-197.000000</td>\n      <td>1.000000</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>-125.000000</td>\n      <td>2.000000</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>93.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>52.000000</td>\n      <td>90.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"CLV: Customer Lifetimes - SnowparkPython","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{"holdout days":{"nuid":"3c61a12d-cf24-431d-b131-7c9579bfc50a","currentValue":"90","widgetInfo":{"widgetType":"text","name":"holdout days","defaultValue":"90","label":null,"options":{"widgetType":"text","validationRegex":null}}}},"notebookOrigID":1632619563207438}},"nbformat":4,"nbformat_minor":0}
